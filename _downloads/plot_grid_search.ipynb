{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nGrid-search and cross-validation\n--------------------------------\nThis examples presents the interface with scikit-learn's GridSearchCV.\n\nIt creates an artificial signal with phase-amplitude coupling (PAC),\nfits a DAR model over a grid-search of parameter, using cross_validation.\n\nCross-validation is done over epochs, with any strategy provided in\nscikit-learn (KFold, ...).\n\nNote that the score computed by a DARSklearn model is the log-likelihood from\nwhich we subtracted the log-likelihood of an autoregressive model at order 0.\nThis is done to have a reference stable over cross-validation splits.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\n\nfrom pactools import simulate_pac\nfrom pactools.grid_search import ExtractDriver, AddDriverDelay\nfrom pactools.grid_search import DARSklearn, MultipleArray\nfrom pactools.grid_search import GridSearchCVProgressBar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first create an artificial signal with PAC.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fs = 200.  # Hz\nhigh_fq = 50.0  # Hz\nlow_fq = 5.0  # Hz\nlow_fq_width = 1.0  # Hz\n\nn_epochs = 3\nn_points = 10000\nnoise_level = 0.4\n\nlow_sig = np.array([\n    simulate_pac(n_points=n_points, fs=fs, high_fq=high_fq, low_fq=low_fq,\n                 low_fq_width=low_fq_width, noise_level=noise_level,\n                 random_state=i) for i in range(n_epochs)\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the model with a scikit-learn's pipeline.\n\nIn a pipeline, the output of each step is given as input to the next one.\nHere #we start with `ExtractDriver`, which extracs the driver with a bandpass\n#filter, and removes it from #the modeled signal with a highpass filter. Then\n#we follow with `AddDriverDelay`, which adds a delay between the driver and\nthe #modeled signal. Finally, we define the DAR model with `DARSklearn`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = Pipeline(steps=[\n    ('driver', ExtractDriver(fs=fs, low_fq=4., max_low_fq=7.,\n                             low_fq_width=low_fq_width, random_state=0)),\n    ('add', AddDriverDelay()),\n    ('dar', DARSklearn(fs=fs, max_ordar=100)),\n])\n\n# grid of parameter on which we will loop\nparam_grid = {\n    'dar__ordar': np.arange(0, 110, 30),\n    'dar__ordriv': [0, 1, 2],\n    'add__delay': [0],\n    'driver__low_fq': [3., 4., 5., 6., 7.],\n    'driver__low_fq_width': [0.25, 0.5, 1.],\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we plug the model into GridSearchCV and we fit it.\n\nThis performs a grid-search with cross-validation: First, multiple train and\ntest sets are defined by the splitting strategy, as defined by the parameter\n`cv` in GridSearchCV. Then, GridSearchCV will loop over each parameter\nconfiguration, fitting the model on one train set and evaluating it on the\ncorresponding test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plug the model and the parameter grid into a GridSearchCV estimator\n# (GridSearchCVProgressBar is identical to GridSearchCV, but it adds a nice\n# progress bar to monitor progress.)\ngscv = GridSearchCVProgressBar(model, param_grid=param_grid,\n                               return_train_score=False, verbose=1)\n\n# Fit the grid-search. We use `MultipleArray` to put together low_sig and\n# high_sig. If high_sig is None, we use low_sig for both the driver and the\n# modeled signal.\nX = MultipleArray(low_sig, None)\ngscv.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the results of the grid search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nBest parameters set found over cross-validation:\\n\")\nprint(gscv.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the results of the grid search.\n\nAs we grid-searched over many dimensions, the results are not easy to\nvisualize. That's why we choose two params to plot and the other are set to\ntheir best values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_results(index='dar__ordar', columns='dar__ordriv'):\n    \"\"\"Select two hyperparameters from which we plot the fluctuations\"\"\"\n    index = 'param_' + index\n    columns = 'param_' + columns\n\n    # prepare the results into a pandas.DataFrame\n    df = pd.DataFrame(gscv.cv_results_)\n\n    # Remove the other by selecting their best values (from gscv.best_params_)\n    other = [c for c in df.columns if c[:6] == 'param_']\n    other.remove(index)\n    other.remove(columns)\n    for col in other:\n        df = df[df[col] == gscv.best_params_[col[6:]]]\n\n    # Create pivot tables for easy plotting\n    table_mean = df.pivot_table(index=index, columns=columns,\n                                values=['mean_test_score'])\n    table_std = df.pivot_table(index=index, columns=columns,\n                               values=['std_test_score'])\n\n    # plot the pivot tables\n    plt.figure()\n    ax = plt.gca()\n    for col_mean, col_std in zip(table_mean.columns, table_std.columns):\n        table_mean[col_mean].plot(ax=ax, yerr=table_std[col_std], marker='o',\n                                  label=col_mean)\n    plt.title('Grid-search results (higher is better)')\n    plt.ylabel('log-likelihood compared to an AR(0)')\n    plt.legend(title=table_mean.columns.names)\n    plt.show()\n\n\nplot_results(index='dar__ordar', columns='dar__ordriv')\nplot_results(index='driver__low_fq', columns='driver__low_fq_width')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}